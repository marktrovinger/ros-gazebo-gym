"""The Gazebo environment

The Gazebo environment is mainly used to connect the simulated Gym environment to the
Gazebo simulator. It takes care of the resets of the simulator after each step or the
resets of the controllers (if needed), it also takes care of all the steps that need to
be done on the simulator when doing a training step or a training reset (typical steps
in the reinforcement learning loop).
"""
import gym
import rospy
from gym.utils import seeding

from openai_ros.core.controllers_connection import ControllersConnection
from openai_ros.core.gazebo_connection import GazeboConnection
from openai_ros.msg import RLExperimentInfo


class RobotGazeboEnv(gym.Env):
    """Connects the simulated environment to the gazebo simulator.

    Args:
        gym (gym.Env): The OpenAi gym environment class.
    """

    def __init__(
        self,
        robot_name_space,
        controllers_list,
        reset_controls,
        start_init_physics_parameters=True,
        reset_world_or_sim="SIMULATION",
    ):
        """Initiate the RobotGazebo environment instance.

        Args:
            robot_name_space (str): The namespace the robot is on.
            controllers_list (list): List with controllers used to control the robot.
            reset_controls (bool): Whether the controllers should be reset when the
                :meth:`RobotGazeboEnv.reset` method is called.
            start_init_physics_parameters (bool, optional): Wether you want to
                initialize the simulation parameters. Defaults to True.
            reset_world_or_sim (str, optional): Wether you want to reset the whole
                simulation "SIMULATION" at startup or only the world "WORLD" (object
                positions). Defaults to "SIMULATION".
        """
        # To reset Simulations
        rospy.logdebug("START init RobotGazeboEnv")
        self.gazebo = GazeboConnection(
            start_init_physics_parameters, reset_world_or_sim
        )
        self.controllers_object = ControllersConnection(
            namespace=robot_name_space, controllers_list=controllers_list
        )
        self.reset_controls = reset_controls
        self.seed()

        # Set up ROS related variables
        self.episode_num = 0
        self.cumulated_episode_reward = 0
        self.reward_pub = rospy.Publisher(
            "/openai/reward", RLExperimentInfo, queue_size=1
        )

        # Un-pause the simulation and reset the controllers if needed
        """To check any topic we need to have the simulations running, we need to do
        two things:
            1) Un-pause the simulation: without that th stream of data doesn't flow.
                This is for simulations that are pause for whatever the reason.
            2) If the simulation was running already for some reason, we need to reset
                the controllers. This has to do with the fact that some plugins with tf,
                don't understand the reset of the simulation and need to be reset to
                work properly.
        """
        self.gazebo.unpause_sim()
        if self.reset_controls:
            self.controllers_object.reset_controllers()

        rospy.logdebug("END init RobotGazeboEnv")

    #############################################
    # Main environment methods ##################
    #############################################
    def seed(self, seed=None):
        """Sets the random seeds used in the gym environment.

        Args:
            seed (int, optional): The seed you want to use for the random number
                generators. Defaults to None.

        Returns:
            list: The used seed.
        """
        self.np_random, seed = seeding.np_random(seed)
        return [seed]

    def step(self, action):
        """Function executed each time step. Here we get the action execute it in a
        time step and retrieve the observations generated by that action.

        Args:
            action (numpy.ndarray): The action we want to perform in the environment.

        Returns:
            (tuple): tuple containing:

                - obs (:obj:`numpy.ndarray`): The current state
                - cost (:obj:`numpy.float64`): The current cost.
                - done (:obj:`bool`): Whether the episode was done.
                - info_dict (:obj:`dict`): Dictionary with additional information.

        .. note::
            Here we should convert the action num to movement action, execute the action
            in the simulation and get the observations result of performing that action.
        """
        rospy.logdebug("START STEP OpenAI ROS")

        self.gazebo.unpause_sim()
        self._set_action(action)
        self.gazebo.pause_sim()
        obs = self._get_obs()
        done = self._is_done(obs)
        info = {}
        reward = self._compute_reward(obs, done)
        self.cumulated_episode_reward += reward

        rospy.logdebug("END STEP OpenAI ROS")

        return obs, reward, done, info

    def _publish_reward_topic(self, reward, episode_number=1):
        """This function publishes the given reward in the reward topic for
        easy access from ROS infrastructure.

        Args:
            reward (float): The reward that was received by taking a given action from
                a given state.
            episode_number (int, optional): The episode number. Defaults to 1.
        """
        reward_msg = RLExperimentInfo()
        reward_msg.episode_number = episode_number
        reward_msg.episode_reward = reward
        self.reward_pub.publish(reward_msg)

    def _update_episode(self):
        """Publishes the cumulated reward of the episode and
        increases the episode number by one.
        """
        rospy.logwarn("PUBLISHING REWARD...")
        self._publish_reward_topic(self.cumulated_episode_reward, self.episode_num)
        rospy.logwarn(
            "PUBLISHING REWARD...DONE="
            + str(self.cumulated_episode_reward)
            + ",EP="
            + str(self.episode_num)
        )

        self.episode_num += 1
        self.cumulated_episode_reward = 0

    def reset(self):
        """Function executed when resetting the environment.
        """
        rospy.logdebug("Reseting RobotGazeboEnvironment")
        self._reset_sim()
        self._init_env_variables()
        self._update_episode()
        obs = self._get_obs()
        rospy.logdebug("END Reseting RobotGazeboEnvironment")
        return obs

    def close(self):
        """Function executed when closing the environment. Use it for closing GUIS and
        other systems that need closing.
        """
        rospy.logdebug("Closing RobotGazeboEnvironment")
        rospy.signal_shutdown("Closing RobotGazeboEnvironment")

    def _reset_sim(self):
        """Resets a simulation.
        """
        rospy.logdebug("RESET SIM START")
        if self.reset_controls:
            rospy.logdebug("RESET CONTROLLERS")
            self.gazebo.unpause_sim()
            self.controllers_object.reset_controllers()
            self._check_all_systems_ready()
            self._set_init_pose()
            self.gazebo.pause_sim()
            self.gazebo.reset_sim()
            self.gazebo.unpause_sim()
            self.controllers_object.reset_controllers()
            self._check_all_systems_ready()
            self.gazebo.pause_sim()

        else:
            rospy.logwarn("DON'T RESET CONTROLLERS")
            self.gazebo.unpause_sim()
            self._check_all_systems_ready()
            self._set_init_pose()
            self.gazebo.pause_sim()
            self.gazebo.reset_sim()
            self.gazebo.unpause_sim()
            self._check_all_systems_ready()
            self.gazebo.pause_sim()

        rospy.logdebug("RESET SIM END")
        return True

    #############################################
    # Extension methods #########################
    #############################################
    # NOTE: These methods CAN be overloaded by robot or task env)
    # - Task environment methods -
    def _set_init_pose(self):
        """Sets the Robot in its init pose.

        Raises:
            NotImplementedError: Thrown when not overloaded by the task environment.
        """
        raise NotImplementedError()

    def _get_obs(self):
        """Returns the observation.

        Raises:
            NotImplementedError: Thrown when not overloaded by the task environment.
        """
        raise NotImplementedError()

    def _init_env_variables(self):
        """Inits variables needed to be initialised each time we reset at the start
        of an episode.

        Raises:
            NotImplementedError: Thrown when not overloaded by the task environment.
        """
        raise NotImplementedError()

    def _set_action(self, action):
        """Applies the given action to the simulation.

        Args:
            action (np.ndarray): The action you want to set.

        Raises:
            NotImplementedError: Thrown When the method was not overloaded by the task
                environment.
        """
        raise NotImplementedError()

    def _is_done(self, observations):
        """Indicates whether or not the episode is done (the robot has fallen for
        example).

        Args:
            observations (np.ndarray): The observations.

        Raises:
            NotImplementedError: Thrown When the method was not overloaded by the task
                environment.
        """
        raise NotImplementedError()

    def _compute_reward(self, observations, done):
        """Calculates the reward to give based on the observations given.

        Args:
            observations (np.ndarray): The observations.
            done (function): Whether the episode was done.

        Raises:
            NotImplementedError: Thrown When the method was not overloaded by the task
                environment.

        """
        raise NotImplementedError()

    # - Robot environment methods -
    def _check_all_systems_ready(self):
        """Checks that all the sensors, publishers and other simulation systems are
        operational.

        Raises:
            NotImplementedError: Thrown when not overloaded by the robot environment.
        """
        raise NotImplementedError()

    def _env_setup(self, initial_qpos):
        """Initial configuration of the environment. Can be used to configure initial state
        and extract information from the simulation.

        Args:
            initial_qpos (np.ndarray): The initial agent pose (generalized coordinates).

        Raises:
            NotImplementedError: Thrown when not overloaded by the robot environment.
        """
        raise NotImplementedError()
